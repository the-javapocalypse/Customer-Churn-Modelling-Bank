{
  "cells": [
    {
      "metadata": {
        "_uuid": "80f37e53017ee3e2a0e83190bee809342618a3d6"
      },
      "cell_type": "markdown",
      "source": "# About Dataset\n\n## Context\nThis is the dataset used in the section \"ANN (Artificial Neural Networks)\" of the Udemy course from Kirill Eremenko (Data Scientist & Forex Systems Expert) and Hadelin de Ponteves (Data Scientist), called Deep Learning A-Z™: Hands-On Artificial Neural Networks. The dataset is very useful for beginners of Machine Learning, and a simple playground where to compare several techniques/skills.\n\nIt can be freely downloaded here: https://www.superdatascience.com/deep-learning/\n\nThe story: A bank is investigating a very high rate of customer leaving the bank. Here is a 10.000 records dataset to investigate and predict which of the customers are more likely to leave the bank soon.\n\n## Acknowledgements\nUdemy instructors Kirill Eremenko (Data Scientist & Forex Systems Expert) and Hadelin de Ponteves (Data Scientist), and their efforts to provide this dataset to their students.\n\n# Solution\nThis problem is solved by using an Artificial Nueral Network (ANN). The instructors of __Deep Learning A-Z™: Hands-On Artificial Neural Networks__ set the milestone for the accuracies as follows:\n* 84% Accuracy = Bronze\n* 85% Accuracy = Silver\n* 86%+ Accuracy = Gold\n\nI tired different topologies for the ANN (Deeper Topology vs Wider Topology. [Read More](https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/)) with the combinations of different optimizers, dropouts etc. and found out that the deeper architecture with no dropout resulted in 86.7% Accuracy. Following is my code."
    },
    {
      "metadata": {
        "_uuid": "eb95fce963add75f05037ec92b86003a287d5009"
      },
      "cell_type": "markdown",
      "source": "Importing Dataset and splitting features and label"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "ebaf97603c932947ad9f8aeb4677722bdf6b070f"
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\n\ndataset = pd.read_csv('../input/Churn_Modelling.csv')\nX = dataset.iloc[:, 3:13].values\ny = dataset.iloc[:, 13].values",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f0e017688cabc0fdab5c2bc369ebf7dd9c8c899a"
      },
      "cell_type": "markdown",
      "source": "Encoding categorical features which are __sex__ & __Geography__. We will also do one hot encoding for __Geography__ to avoid dummy variable trap"
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "fb07303fc25cc75a1ab5a3cad8520a1427c80f4b"
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\nlabelencoder_X_1 = LabelEncoder()\nX[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\nlabelencoder_X_2 = LabelEncoder()\nX[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n\nonehotencoder = OneHotEncoder(categorical_features=[1])\nX = onehotencoder.fit_transform(X).toarray()",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d1c43da25a48adc877d8a9d82cf8f8b8827661fc"
      },
      "cell_type": "markdown",
      "source": "Splitting into training and testing sets"
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "6873e0f40fbe1856464b50c5094b864b0979bc68"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "e2b6f7a4c2c2ba246dbfd0c5d4344f5dfe8b422d"
      },
      "cell_type": "code",
      "source": "Applying features scaling",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "c621e2e74e5e0ee2e01633c57ecee945c57393bc"
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c6d5d572646d8b5626a29e121dcbf917e52dc523"
      },
      "cell_type": "markdown",
      "source": "Defining architecture for our neural network"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "3e70462bc6e5303d97f5e1f62e47e7acdda4ef4f"
      },
      "cell_type": "code",
      "source": "from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n\ndef deep_model():\n    classifier = Sequential()\n    classifier.add(Dense(units=12, kernel_initializer='uniform', activation='relu', input_dim=12))\n    classifier.add(Dense(units=12, kernel_initializer='uniform', activation='relu'))\n    classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n    classifier.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n    return classifier",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "15d357855e1841b356bb76b72050a708d5e230fd"
      },
      "cell_type": "markdown",
      "source": "Running our ANN"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3c341ceb199272b86f888c86647a0d6ededc3796"
      },
      "cell_type": "code",
      "source": "classifier = deep_model()\nclassifier.fit(X_train, y_train, batch_size=4, epochs=128)\n\n\ny_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)\n\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\n\naccuracy = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1])\nprint(\"Accuracy: \"+ str(accuracy*100)+\"%\")",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch 1/128\n8000/8000 [==============================] - 3s 353us/step - loss: 0.4553 - acc: 0.7955\nEpoch 2/128\n8000/8000 [==============================] - 3s 335us/step - loss: 0.4242 - acc: 0.8140\nEpoch 3/128\n8000/8000 [==============================] - 3s 339us/step - loss: 0.4197 - acc: 0.8295\nEpoch 4/128\n8000/8000 [==============================] - 3s 335us/step - loss: 0.4150 - acc: 0.8315\nEpoch 5/128\n8000/8000 [==============================] - 3s 335us/step - loss: 0.4103 - acc: 0.8330\nEpoch 6/128\n8000/8000 [==============================] - 3s 333us/step - loss: 0.4066 - acc: 0.8334\nEpoch 7/128\n8000/8000 [==============================] - 3s 330us/step - loss: 0.4052 - acc: 0.8360\nEpoch 8/128\n8000/8000 [==============================] - 3s 334us/step - loss: 0.4019 - acc: 0.8386\nEpoch 9/128\n8000/8000 [==============================] - 3s 330us/step - loss: 0.4020 - acc: 0.8357\nEpoch 10/128\n8000/8000 [==============================] - 3s 329us/step - loss: 0.3982 - acc: 0.8394\nEpoch 11/128\n8000/8000 [==============================] - 3s 329us/step - loss: 0.4016 - acc: 0.8384\nEpoch 12/128\n8000/8000 [==============================] - 3s 329us/step - loss: 0.3992 - acc: 0.8376\nEpoch 13/128\n8000/8000 [==============================] - 3s 328us/step - loss: 0.3999 - acc: 0.8366\nEpoch 14/128\n8000/8000 [==============================] - 3s 327us/step - loss: 0.3988 - acc: 0.8397\nEpoch 15/128\n8000/8000 [==============================] - 3s 327us/step - loss: 0.3979 - acc: 0.8393\nEpoch 16/128\n8000/8000 [==============================] - 3s 327us/step - loss: 0.3996 - acc: 0.8409\nEpoch 17/128\n8000/8000 [==============================] - 3s 331us/step - loss: 0.3975 - acc: 0.8387\nEpoch 18/128\n8000/8000 [==============================] - 3s 335us/step - loss: 0.3978 - acc: 0.8409\nEpoch 19/128\n8000/8000 [==============================] - 3s 331us/step - loss: 0.3976 - acc: 0.8415\nEpoch 20/128\n8000/8000 [==============================] - 3s 333us/step - loss: 0.3979 - acc: 0.8397\nEpoch 21/128\n8000/8000 [==============================] - 3s 338us/step - loss: 0.3969 - acc: 0.8421\nEpoch 22/128\n8000/8000 [==============================] - 3s 333us/step - loss: 0.3970 - acc: 0.8391\nEpoch 23/128\n8000/8000 [==============================] - 3s 338us/step - loss: 0.3969 - acc: 0.8410\nEpoch 24/128\n8000/8000 [==============================] - 3s 340us/step - loss: 0.3967 - acc: 0.8426\nEpoch 25/128\n8000/8000 [==============================] - 3s 334us/step - loss: 0.3957 - acc: 0.8399\nEpoch 26/128\n8000/8000 [==============================] - 3s 334us/step - loss: 0.3960 - acc: 0.8431\nEpoch 27/128\n8000/8000 [==============================] - 3s 332us/step - loss: 0.3970 - acc: 0.8424\nEpoch 28/128\n8000/8000 [==============================] - 3s 332us/step - loss: 0.3960 - acc: 0.8432\nEpoch 29/128\n8000/8000 [==============================] - 3s 333us/step - loss: 0.3959 - acc: 0.8424\nEpoch 30/128\n8000/8000 [==============================] - 3s 332us/step - loss: 0.3957 - acc: 0.8407\nEpoch 31/128\n8000/8000 [==============================] - 3s 334us/step - loss: 0.3959 - acc: 0.8416\nEpoch 32/128\n8000/8000 [==============================] - 3s 334us/step - loss: 0.3942 - acc: 0.8435\nEpoch 33/128\n8000/8000 [==============================] - 3s 334us/step - loss: 0.3947 - acc: 0.8419\nEpoch 34/128\n8000/8000 [==============================] - 3s 335us/step - loss: 0.3943 - acc: 0.8445\nEpoch 35/128\n8000/8000 [==============================] - 3s 334us/step - loss: 0.3942 - acc: 0.8434\nEpoch 36/128\n8000/8000 [==============================] - 3s 331us/step - loss: 0.3943 - acc: 0.8450\nEpoch 37/128\n8000/8000 [==============================] - 3s 334us/step - loss: 0.3932 - acc: 0.8438\nEpoch 38/128\n8000/8000 [==============================] - 3s 334us/step - loss: 0.3958 - acc: 0.8432\nEpoch 39/128\n8000/8000 [==============================] - 3s 335us/step - loss: 0.3953 - acc: 0.8446\nEpoch 40/128\n8000/8000 [==============================] - 3s 337us/step - loss: 0.3937 - acc: 0.8427\nEpoch 41/128\n8000/8000 [==============================] - 3s 338us/step - loss: 0.3933 - acc: 0.8449\nEpoch 42/128\n8000/8000 [==============================] - 3s 334us/step - loss: 0.3938 - acc: 0.8444\nEpoch 43/128\n8000/8000 [==============================] - 3s 333us/step - loss: 0.3934 - acc: 0.8443\nEpoch 44/128\n8000/8000 [==============================] - 3s 334us/step - loss: 0.3947 - acc: 0.8448\nEpoch 45/128\n8000/8000 [==============================] - 3s 336us/step - loss: 0.3940 - acc: 0.8438\nEpoch 46/128\n8000/8000 [==============================] - 3s 324us/step - loss: 0.3947 - acc: 0.8436\nEpoch 47/128\n8000/8000 [==============================] - 3s 326us/step - loss: 0.3947 - acc: 0.8429\nEpoch 48/128\n8000/8000 [==============================] - 3s 326us/step - loss: 0.3942 - acc: 0.8448\nEpoch 49/128\n8000/8000 [==============================] - 3s 328us/step - loss: 0.3963 - acc: 0.8439\nEpoch 50/128\n8000/8000 [==============================] - 3s 329us/step - loss: 0.3954 - acc: 0.8440\nEpoch 51/128\n8000/8000 [==============================] - 3s 327us/step - loss: 0.3964 - acc: 0.8436\nEpoch 52/128\n8000/8000 [==============================] - 3s 329us/step - loss: 0.3972 - acc: 0.8449\nEpoch 53/128\n8000/8000 [==============================] - 3s 328us/step - loss: 0.3967 - acc: 0.8439\nEpoch 54/128\n8000/8000 [==============================] - 3s 329us/step - loss: 0.3967 - acc: 0.8444\nEpoch 55/128\n8000/8000 [==============================] - 3s 330us/step - loss: 0.3945 - acc: 0.8441\nEpoch 56/128\n8000/8000 [==============================] - 3s 329us/step - loss: 0.3967 - acc: 0.8460\nEpoch 57/128\n8000/8000 [==============================] - 3s 331us/step - loss: 0.3953 - acc: 0.8450\nEpoch 58/128\n8000/8000 [==============================] - 3s 331us/step - loss: 0.3949 - acc: 0.8476\nEpoch 59/128\n8000/8000 [==============================] - 3s 328us/step - loss: 0.3936 - acc: 0.8471\nEpoch 60/128\n8000/8000 [==============================] - 3s 328us/step - loss: 0.3925 - acc: 0.8499\nEpoch 61/128\n8000/8000 [==============================] - 3s 328us/step - loss: 0.3905 - acc: 0.8495\nEpoch 62/128\n8000/8000 [==============================] - 3s 329us/step - loss: 0.3910 - acc: 0.8480\nEpoch 63/128\n8000/8000 [==============================] - 3s 325us/step - loss: 0.3896 - acc: 0.8468\nEpoch 64/128\n8000/8000 [==============================] - 3s 324us/step - loss: 0.3887 - acc: 0.8495\nEpoch 65/128\n8000/8000 [==============================] - 3s 328us/step - loss: 0.3893 - acc: 0.8458\nEpoch 66/128\n8000/8000 [==============================] - 3s 330us/step - loss: 0.3858 - acc: 0.8501\nEpoch 67/128\n8000/8000 [==============================] - 3s 327us/step - loss: 0.3824 - acc: 0.8514\nEpoch 68/128\n8000/8000 [==============================] - 3s 326us/step - loss: 0.3772 - acc: 0.8544\nEpoch 69/128\n8000/8000 [==============================] - 3s 333us/step - loss: 0.3731 - acc: 0.8549\nEpoch 70/128\n8000/8000 [==============================] - 3s 331us/step - loss: 0.3659 - acc: 0.8596\nEpoch 71/128\n8000/8000 [==============================] - 3s 334us/step - loss: 0.3611 - acc: 0.8614\nEpoch 72/128\n8000/8000 [==============================] - 3s 343us/step - loss: 0.3565 - acc: 0.8618\nEpoch 73/128\n8000/8000 [==============================] - 3s 332us/step - loss: 0.3518 - acc: 0.8635\nEpoch 74/128\n8000/8000 [==============================] - 3s 331us/step - loss: 0.3496 - acc: 0.8650\nEpoch 75/128\n8000/8000 [==============================] - 3s 329us/step - loss: 0.3468 - acc: 0.8656\nEpoch 76/128\n8000/8000 [==============================] - 3s 330us/step - loss: 0.3454 - acc: 0.8662\nEpoch 77/128\n8000/8000 [==============================] - 3s 329us/step - loss: 0.3466 - acc: 0.8665\nEpoch 78/128\n8000/8000 [==============================] - 3s 332us/step - loss: 0.3457 - acc: 0.8636\nEpoch 79/128\n8000/8000 [==============================] - 3s 332us/step - loss: 0.3462 - acc: 0.8666\nEpoch 80/128\n8000/8000 [==============================] - 3s 334us/step - loss: 0.3455 - acc: 0.8664\nEpoch 81/128\n8000/8000 [==============================] - 3s 330us/step - loss: 0.3483 - acc: 0.8654\nEpoch 82/128\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "8000/8000 [==============================] - 3s 327us/step - loss: 0.3468 - acc: 0.8662\nEpoch 83/128\n8000/8000 [==============================] - 3s 334us/step - loss: 0.3475 - acc: 0.8660\nEpoch 84/128\n8000/8000 [==============================] - 3s 334us/step - loss: 0.3476 - acc: 0.8667\nEpoch 85/128\n8000/8000 [==============================] - 3s 337us/step - loss: 0.3478 - acc: 0.8656\nEpoch 86/128\n8000/8000 [==============================] - 3s 331us/step - loss: 0.3448 - acc: 0.8672\nEpoch 87/128\n7848/8000 [============================>.] - ETA: 0s - loss: 0.3452 - acc: 0.8668",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "4dadd782e7a208689ef104c4bd41a570bd8d07a3"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}